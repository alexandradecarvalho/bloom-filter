{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bloom Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Problem:\n",
    "With **bloom filters**, the aim is to solve the **belonging problem**: we want to check whether or not an element is part of a set.\n",
    "With big sets of data, linear search (storing a list of elements and then looking through it) can be reeaaaaly slow - and exceed memory!\n",
    "\n",
    "The way this solution works is, when we only need to know if a element belongs to the set (\"YES\"/\"NO\" answer), we can leave out the storing of the elements and start only storing binary information   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bloom Filters:\n",
    "Bloom filters use **hash functions** to calculate a vector of bits that represents the set. The element is \"stored\" in the vector by setting all the values returned by the hash functions to 1. The belonging in the set is determined by the contents of the vector in the positions returned by the hash functions applied to the element we're searching. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run if mmh3 isn't installed on your computer\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install mmh3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import mmh3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hash Functions:\n",
    "It is important to choose our hash functions wisely. First of all, it has to select all elements of the vector with the same probability, so **they must be uniformely distributed**. Then, it's important that our hash functions are independent among them, otherwise it would be the same as just using **one** hash function. \n",
    "\n",
    "In this work we used the murmur function with different seeds, mainly because it fills the criteria and because it's fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Number of Hash Functions:\n",
    "\n",
    "$ optimal_k = (0.693*n)/m $\n",
    "\n",
    "This limits the lower limit for the error probability: $ optimal_p = 2^{(-optimal_k)} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BloomFilter(object):\n",
    "    def __init__(self, nitems, false_positive_prob):\n",
    "        self.size = int(-(nitems * numpy.log(false_positive_prob))/(numpy.log(2)**2))+1 # size of the bloom filter\n",
    "        self.nhash = int((0.639*self.size)/nitems)+1 # number of hash functions\n",
    "\n",
    "        self.bloomf = numpy.zeros(self.size) # initializing the bloom filter as an array of size self.size with everything at 0\n",
    " \n",
    "    def add(self, item):\n",
    "        for i in range(self.nhash):\n",
    "            h = mmh3.hash(item, i) % self.size #i = seed\n",
    "            self.bloomf[h] = 1\n",
    " \n",
    "    def check(self, item):\n",
    "        for i in range(self.nhash):\n",
    "\n",
    "            h = mmh3.hash(item, i) % self.size\n",
    "\n",
    "            if self.bloomf[h] == 0:\n",
    "                return False\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = pd.read_csv(\"dataset/dset.csv\", chunksize= 1000000)\n",
    "our_set = pd.concat(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Subjects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A tale of two friends</td>\n",
       "      <td>O'Ryan, Ellie</td>\n",
       "      <td>Musicians Fiction, Bullfighters Fiction, Best ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Naruto. Vol. 1, Uzumaki Naruto</td>\n",
       "      <td>Kishimoto, Masashi</td>\n",
       "      <td>Ninja Japan Comic books strips etc, Comic book...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Peace, love &amp; Wi-Fi : a ZITS treasury</td>\n",
       "      <td>Scott, Jerry</td>\n",
       "      <td>Duncan Jeremy Fictitious character Comic books...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Paris pilgrims : a novel</td>\n",
       "      <td>Carlile, Clancy</td>\n",
       "      <td>Hemingway Ernest 1899 1961 Fiction, Biographic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Erotic by nature : a celebration of life, of l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Erotic literature American, American literatur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Title  \\\n",
       "0           0                             A tale of two friends    \n",
       "1           1                    Naruto. Vol. 1, Uzumaki Naruto    \n",
       "2           2             Peace, love & Wi-Fi : a ZITS treasury    \n",
       "3           3                      The Paris pilgrims : a novel    \n",
       "4           4  Erotic by nature : a celebration of life, of l...   \n",
       "\n",
       "               Author                                           Subjects  \n",
       "0       O'Ryan, Ellie  Musicians Fiction, Bullfighters Fiction, Best ...  \n",
       "1  Kishimoto, Masashi  Ninja Japan Comic books strips etc, Comic book...  \n",
       "2        Scott, Jerry  Duncan Jeremy Fictitious character Comic books...  \n",
       "3     Carlile, Clancy  Hemingway Ernest 1899 1961 Fiction, Biographic...  \n",
       "4                 NaN  Erotic literature American, American literatur...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Results:\n",
    "Being a probabilistic approach, bloom filters allow for **false positives**, values that are considered as being in the set when in reality they don't. This is caused by  \"**collisions**\", when two different symbols produce the same hash code. A way of minimizing this is by using multiple hash functions, at expenses of more memory usage.\n",
    "\n",
    "\n",
    "The false positive rate is diminished by more hash functions only until an optimal value is reached. After that, the rate rises again because there start to be too many 1s for the same element. \n",
    "\n",
    "\n",
    "On the other hand, bloom filters don't allow for **false negatives**: if a position in the vector (or one of them) wasn't set as 1, then we can be sure that that element wasn't mapped into the vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability of False Positives:\n",
    "Being m the set dimension, n the number of positions in the vector, and k the number of hash functions,\n",
    "\n",
    "\n",
    "the probability of false positives can be given by:\n",
    "$ p(m,n,k) = (1-e^{(-k*m)/n})^k $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "14428183\n"
     ]
    }
   ],
   "source": [
    "n = len(our_set) \n",
    "p = 0.001 #false positive probability\n",
    "\n",
    "titles_bf = BloomFilter(n,p)\n",
    "print(titles_bf.nhash)\n",
    "print(titles_bf.size)\n",
    "\n",
    "authors_bf = BloomFilter(n,p)\n",
    "subjects_bf = BloomFilter(n,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_object = open('subjects.txt', 'a')\n",
    "for _,item in our_set.iterrows():\n",
    "    title = item[\"Title\"]\n",
    "    author = item[\"Author\"]\n",
    "    subjects = item[\"Subjects\"]\n",
    "\n",
    "    if title and isinstance(title, str):\n",
    "        titles_bf.add(title)\n",
    "\n",
    "    if author and isinstance(author, str):\n",
    "        authors_bf.add(author)\n",
    "\n",
    "    if subjects and isinstance(subjects, str):\n",
    "        sub_list = str(subjects).split(\", \")\n",
    "        for subject in sub_list:\n",
    "            subjects_bf.add(subject)\n",
    "file_object.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Case\n",
    "Searching if in the Seattle Public Library there is a certain book, there is a some book from a certain author or if there is a book about a certain subject. \n",
    "\n",
    "For this purpose, you can search by Title, Author or Subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ WELCOME TO OUR LIBRARY ------------------------------\n",
      "1. Search by Title\n",
      "2. Search by Author\n",
      "3. Search by Subject\n",
      "0. Exit\n",
      "------------------------------------------------------------------------------------\n",
      "See you soon!\n"
     ]
    }
   ],
   "source": [
    "def print_menu():\n",
    "    print(30 * \"-\" , \"WELCOME TO OUR LIBRARY\" , 30 * \"-\")\n",
    "    print(\"1. Search by Title\")\n",
    "    print(\"2. Search by Author\")\n",
    "    print(\"3. Search by Subject\")\n",
    "    print(\"0. Exit\")\n",
    "    print(84 * \"-\")\n",
    "\n",
    "print_menu()\n",
    "\n",
    "def main():\n",
    "    loop = True\n",
    "\n",
    "    while loop:\n",
    "        try:\n",
    "            choice = int(input(\"Enter your choice [1-3] or 0 to quit: \"))\n",
    "        except:\n",
    "            choice = 222\n",
    "        \n",
    "        if choice==1:     \n",
    "            inpt = input(\"Enter the title: \")\n",
    "            if titles_bf.check(inpt):\n",
    "                print(\"The searched book is in our library!\")\n",
    "            else:\n",
    "                print(\"We're sorry, but we didn't find a result.\")\n",
    "        elif choice==2:     \n",
    "            inpt = input(\"Enter the author: \")\n",
    "\n",
    "            # if name is introduced \"raw\" (first + space + last), we transform it into last + comma + space + first\n",
    "            if len(inpt.split(\",\")) == 1 and len(inpt.split(\" \")) > 1: # 2 names but no comma separation\n",
    "                inpt = \", \".join(inpt.split(\" \")[::-1])\n",
    "            \n",
    "            if authors_bf.check(inpt):\n",
    "                print(\"We have books of the searched author in our library!\")\n",
    "            else:\n",
    "                print(\"We're sorry, but we didn't find a result.\")\n",
    "        elif choice==3:     \n",
    "            inpt = input(\"Enter the subject: \")\n",
    "            if subjects_bf.check(inpt):\n",
    "                print(\"We have books about the searched subject in our library!\")\n",
    "            else:\n",
    "                print(\"We're sorry, but we didn't find a result.\")\n",
    "        elif choice==0:\n",
    "            print(\"See you soon!\")\n",
    "            break\n",
    "        else:\n",
    "            # Any inputs other than values 0-3 we print an error message\n",
    "            print(\"Wrong option selected.\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Conclusions:\n",
    "#### Limitations:\n",
    "* We need to know the maximum number of elements to store in the vector beforehand\n",
    "* The number of false positives can rapidly increase, but this can be traded off with the number of hash functions and space to store the vector \n",
    "\n",
    "#### Upsides:\n",
    "* It's a really fast method\n",
    "* It has a relatively low error rate\n",
    "* It works for a big dataset"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
